{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sinLZ4ZRDz9z"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this tutorial, we will implement a type of graph neural network (GNN) known as\n",
        "_ message passing neural network_ (MPNN) to predict graph properties. Specifically, we will\n",
        "implement an MPNN to predict a molecular property known as\n",
        "_blood-brain barrier permeability_ (BBBP).\n",
        "\n",
        "Motivation: as molecules are naturally represented as an undirected graph `G = (V, E)`,\n",
        "where `V` is a set or vertices (nodes; atoms) and `E` a set of edges (bonds), GNNs (such\n",
        "as MPNN) are proving to be a useful method for predicting molecular properties.\n",
        "\n",
        "Until now, more traditional methods, such as random forests, support vector machines, etc.,\n",
        "have been commonly used to predict molecular properties. In contrast to GNNs, these\n",
        "traditional approaches often operate on precomputed molecular features such as\n",
        "molecular weight, polarity, charge, number of carbon atoms, etc. Although these\n",
        "molecular features prove to be good predictors for various molecular properties, it is\n",
        "hypothesized that operating on these more \"raw\", \"low-level\", features could prove even\n",
        "better.\n",
        "\n",
        "### References\n",
        "\n",
        "In recent years, a lot of effort has been put into developing neural networks for\n",
        "graph data, including molecular graphs. For a summary of graph neural networks, see e.g.,\n",
        "[A Comprehensive Survey on Graph Neural Networks](https://arxiv.org/abs/1901.00596) and\n",
        "[Graph Neural Networks: A Review of Methods and Applications](https://arxiv.org/abs/1812.08434);\n",
        "and for further reading on the specific\n",
        "graph neural network implemented in this tutorial see\n",
        "[Neural Message Passing for Quantum Chemistry](https://arxiv.org/abs/1704.01212) and\n",
        "[DeepChem's MPNNModel](https://deepchem.readthedocs.io/en/latest/api_reference/models.html#mpnnmodel)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU_A1plGDz92"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "mERLPiEqDz92"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Temporary suppress tf logs\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from rdkit import Chem\n",
        "from rdkit import RDLogger\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from rdkit.Chem.Draw import MolsToGridImage\n",
        "\n",
        "try:\n",
        "    import rdkit\n",
        "    from rdkit import Chem\n",
        "    from rdkit.Chem import AllChem\n",
        "    from rdkit import rdBase\n",
        "    from rdkit.Chem.rdchem import HybridizationType\n",
        "    from rdkit import RDConfig\n",
        "    from rdkit.Chem import ChemicalFeatures\n",
        "    from rdkit.Chem.rdchem import BondType as BT\n",
        "    from rdkit.Chem import Draw\n",
        "    rdBase.DisableLog('rdApp.error')\n",
        "except ImportError:\n",
        "    rdkit = None\n",
        "\n",
        "# Temporary suppress warnings and RDKit logs\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "RDLogger.DisableLog(\"rdApp.*\")\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BqIURJODz94"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Information about the dataset can be found in\n",
        "[A Bayesian Approach to in Silico Blood-Brain Barrier Penetration Modeling](https://pubs.acs.org/doi/10.1021/ci300124c)\n",
        "and [MoleculeNet: A Benchmark for Molecular Machine Learning](https://arxiv.org/abs/1703.00564).\n",
        "The dataset will be downloaded from [MoleculeNet.org](https://moleculenet.org/datasets-1).\n",
        "\n",
        "### About\n",
        "\n",
        "The dataset contains **2,050** molecules. Each molecule come with a **name**, **label**\n",
        "and **SMILES** string.\n",
        "\n",
        "The blood-brain barrier (BBB) is a membrane separating the blood from the brain\n",
        "extracellular fluid, hence blocking out most drugs (molecules) from reaching\n",
        "the brain. Because of this, the BBBP has been important to study for the development of\n",
        "new drugs that aim to target the central nervous system. The labels for this\n",
        "data set are binary (1 or 0) and indicate the permeability of the molecules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qMON-g2BDz94"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Smiles</th>\n",
              "      <th>Tb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCC(O)CCC(F)(F)F</td>\n",
              "      <td>413.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CCC(CC)ON(=O)=O</td>\n",
              "      <td>413.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Clc1ccc(Cl)c(c1)C(=O)O</td>\n",
              "      <td>574.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NC(C)Cc1ccccc1</td>\n",
              "      <td>476.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>COc1ccc(cc1)NC(=O)C</td>\n",
              "      <td>608.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5271</th>\n",
              "      <td>BrC(F)(F)Oc1ccc(cc1)C(C)(C)COCc2cccc(Oc3ccccc3)c2</td>\n",
              "      <td>564.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5272</th>\n",
              "      <td>OCC(C)CC(F)(F)F</td>\n",
              "      <td>405.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5273</th>\n",
              "      <td>Clc1ccc(cc1)CC2CCC(C)(C)C2(O)CN3C=NC=N3</td>\n",
              "      <td>558.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5274</th>\n",
              "      <td>CCOC(=O)C(Cl)Cc1cc(c(F)cc1Cl)N2N=C(C)N(C(F)F)C2=O</td>\n",
              "      <td>625.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5275</th>\n",
              "      <td>CSC(=O)c1cccc2N=NSc12</td>\n",
              "      <td>540.15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5276 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Smiles      Tb\n",
              "0                                      CCC(O)CCC(F)(F)F  413.80\n",
              "1                                       CCC(CC)ON(=O)=O  413.15\n",
              "2                                Clc1ccc(Cl)c(c1)C(=O)O  574.15\n",
              "3                                        NC(C)Cc1ccccc1  476.15\n",
              "4                                   COc1ccc(cc1)NC(=O)C  608.15\n",
              "...                                                 ...     ...\n",
              "5271  BrC(F)(F)Oc1ccc(cc1)C(C)(C)COCc2cccc(Oc3ccccc3)c2  564.15\n",
              "5272                                    OCC(C)CC(F)(F)F  405.65\n",
              "5273            Clc1ccc(cc1)CC2CCC(C)(C)C2(O)CN3C=NC=N3  558.15\n",
              "5274  CCOC(=O)C(Cl)Cc1cc(c(F)cc1Cl)N2N=C(C)N(C(F)F)C2=O  625.65\n",
              "5275                              CSC(=O)c1cccc2N=NSc12  540.15\n",
              "\n",
              "[5276 rows x 2 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = pd.read_csv('../data/raw_data.csv',low_memory=False)\n",
        "dataset = pd.concat([dataset['Smiles'], dataset['Tb']], axis=1)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGni4D3KDz95"
      },
      "source": [
        "### Define features\n",
        "\n",
        "To encode features for atoms and bonds (which we will need later),\n",
        "we'll define two classes: `AtomFeaturizer` and `BondFeaturizer` respectively.\n",
        "\n",
        "To reduce the lines of code, i.e., to keep this tutorial short and concise,\n",
        "only about a handful of (atom and bond) features will be considered: \\[atom features\\]\n",
        "[symbol (element)](https://en.wikipedia.org/wiki/Chemical_element),\n",
        "[number of valence electrons](https://en.wikipedia.org/wiki/Valence_electron),\n",
        "[number of hydrogen bonds](https://en.wikipedia.org/wiki/Hydrogen),\n",
        "[orbital hybridization](https://en.wikipedia.org/wiki/Orbital_hybridisation),\n",
        "\\[bond features\\]\n",
        "[(covalent) bond type](https://en.wikipedia.org/wiki/Covalent_bond), and\n",
        "[conjugation](https://en.wikipedia.org/wiki/Conjugated_system)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "K7dErudnDz95"
      },
      "outputs": [],
      "source": [
        "# Done\n",
        "class Featurizer:\n",
        "    def __init__(self, allowable_sets):\n",
        "        self.dim = 0\n",
        "        self.features_mapping = {}\n",
        "        for k, s in allowable_sets.items():\n",
        "            s = sorted(list(s))\n",
        "            self.features_mapping[k] = dict(zip(s, range(self.dim, len(s) + self.dim)))\n",
        "            self.dim += len(s)\n",
        "\n",
        "    def encode(self, inputs):\n",
        "        output = np.zeros((self.dim,))\n",
        "        for name_feature, feature_mapping in self.features_mapping.items():\n",
        "            feature = getattr(self, name_feature)(inputs)\n",
        "            if feature not in feature_mapping:\n",
        "                continue\n",
        "            output[feature_mapping[feature]] = 1.0\n",
        "        return output\n",
        "\n",
        "# Atom features class\n",
        "class AtomFeature_encode(Featurizer):\n",
        "    def __init__(self, allowable_sets):\n",
        "        super().__init__(allowable_sets)\n",
        "\n",
        "    def atom_list(self, atom):\n",
        "        return atom.GetSymbol()\n",
        "\n",
        "    def n_bonds(self, atom):\n",
        "        return atom.GetImplicitValence()\n",
        "\n",
        "    def numH_list(self, atom):\n",
        "        return atom.GetTotalNumHs()\n",
        "\n",
        "    def hybridization(self, atom):\n",
        "        return atom.GetHybridization().name.lower()\n",
        "    \n",
        "    def aromatic(self,atom):\n",
        "        return atom.GetIsAromatic()\n",
        "    \n",
        "    def ring(self,atom):\n",
        "        return atom.IsInRing()\n",
        "    \n",
        "    def formal_charge(self,atom):\n",
        "        return atom.GetFormalCharge()\n",
        "\n",
        "\n",
        "class BondFeature_encode(Featurizer):\n",
        "    def __init__(self, allowable_sets):\n",
        "        super().__init__(allowable_sets)\n",
        "        self.dim += 1\n",
        "\n",
        "    def encode(self, bond):\n",
        "        output = np.zeros((self.dim,))\n",
        "        if bond is None:\n",
        "            output[-1] = 1.0\n",
        "            return output\n",
        "        output = super().encode(bond)\n",
        "        return output\n",
        "\n",
        "    def bond_type(self, bond):\n",
        "        return bond.GetBondType().name.lower()\n",
        "\n",
        "    def conjugated(self, bond):\n",
        "        return bond.GetIsConjugated()\n",
        "    \n",
        "    def inring(self,bond):\n",
        "        return bond.IsInRing()\n",
        "    \n",
        "    def stereo(self,bond):\n",
        "        return str(bond.GetStereo()).upper()\n",
        "\n",
        "\n",
        "atom_featurizer = AtomFeature_encode(\n",
        "    allowable_sets={\n",
        "        \"atom_list\": {'H','C', 'O', 'F','N','Cl','P','S','Si','Br','I'},\n",
        "        \"n_bonds\": {0, 1, 2, 3, 4, 5},\n",
        "        \"numH_list\": {0, 1, 2, 3, 4},\n",
        "        \"hybridization\": {\"sp\", \"sp2\", \"sp3\",\"sp3d2\"},\n",
        "        \"aromatic\":{True, False},\n",
        "        \"ring\":{True, False},\n",
        "        \"formal_charge\": {-4,-3, -2, -1, 0, 1, 2, 3, 4},\n",
        "    }\n",
        ")\n",
        "\n",
        "bond_featurizer = BondFeature_encode(\n",
        "    allowable_sets={\n",
        "        \"bond_type\": {\"single\", \"double\", \"triple\", \"aromatic\"},\n",
        "        \"inring\": {True, False},\n",
        "        \"conjugated\": {True, False},\n",
        "        \"stereo\": {\"STEREONONE\", \"STEREOANY\", \"STEREOZ\", \"STEREOE\"},\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGAM6OumDz96"
      },
      "source": [
        "### Generate graphs\n",
        "\n",
        "Before we can generate complete graphs from SMILES, we need to implement the following functions:\n",
        "\n",
        "1. `molecule_from_smiles`, which takes as input a SMILES and returns a molecule object.\n",
        "This is all handled by RDKit.\n",
        "\n",
        "2. `graph_from_molecule`, which takes as input a molecule object and returns a graph,\n",
        "represented as a three-tuple (atom_features, bond_features, pair_indices). For this we\n",
        "will make use of the classes defined previously.\n",
        "\n",
        "Finally, we can now implement the function `graphs_from_smiles`, which applies function (1)\n",
        "and subsequently (2) on all SMILES of the training, validation and test datasets.\n",
        "\n",
        "Notice: although scaffold splitting is recommended for this data set (see\n",
        "[here](https://arxiv.org/abs/1703.00564)), for simplicity, simple random splittings were\n",
        "performed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "VRPyZB9oDz97"
      },
      "outputs": [],
      "source": [
        "\n",
        "def molecule_from_smiles(smiles):\n",
        "    # MolFromSmiles(m, sanitize=True) should be equivalent to\n",
        "    # MolFromSmiles(m, sanitize=False) -> SanitizeMol(m) -> AssignStereochemistry(m, ...)\n",
        "    molecule = Chem.MolFromSmiles(smiles, sanitize=False)\n",
        "\n",
        "    # If sanitization is unsuccessful, catch the error, and try again without\n",
        "    # the sanitization step that caused the error\n",
        "    flag = Chem.SanitizeMol(molecule, catchErrors=True)\n",
        "    if flag != Chem.SanitizeFlags.SANITIZE_NONE:\n",
        "        Chem.SanitizeMol(molecule, sanitizeOps=Chem.SanitizeFlags.SANITIZE_ALL ^ flag)\n",
        "\n",
        "    Chem.AssignStereochemistry(molecule, cleanIt=True, force=True)\n",
        "    return molecule\n",
        "\n",
        "\n",
        "def graph_from_molecule(molecule):\n",
        "    # Initialize graph\n",
        "    atom_features = []\n",
        "    bond_features = []\n",
        "    pair_indices = []\n",
        "\n",
        "    for atom in molecule.GetAtoms():\n",
        "        atom_features.append(atom_featurizer.encode(atom))\n",
        "\n",
        "        # Add self-loops\n",
        "        pair_indices.append([atom.GetIdx(), atom.GetIdx()])\n",
        "        bond_features.append(bond_featurizer.encode(None))\n",
        "\n",
        "        for neighbor in atom.GetNeighbors():\n",
        "            bond = molecule.GetBondBetweenAtoms(atom.GetIdx(), neighbor.GetIdx())\n",
        "            pair_indices.append([atom.GetIdx(), neighbor.GetIdx()])\n",
        "            bond_features.append(bond_featurizer.encode(bond))\n",
        "\n",
        "    return np.array(atom_features), np.array(bond_features), np.array(pair_indices)\n",
        "\n",
        "\n",
        "def graphs_from_smiles(smiles_list):\n",
        "    # Initialize graphs\n",
        "    atom_features_list = []\n",
        "    bond_features_list = []\n",
        "    pair_indices_list = []\n",
        "\n",
        "    for smiles in smiles_list:\n",
        "        molecule = molecule_from_smiles(smiles)\n",
        "        atom_features, bond_features, pair_indices = graph_from_molecule(molecule)\n",
        "\n",
        "        atom_features_list.append(atom_features)\n",
        "        bond_features_list.append(bond_features)\n",
        "        pair_indices_list.append(pair_indices)\n",
        "\n",
        "    # Convert lists to ragged tensors for tf.data.Dataset later on\n",
        "    return (\n",
        "        tf.ragged.constant(atom_features_list, dtype=tf.float32),\n",
        "        tf.ragged.constant(bond_features_list, dtype=tf.float32),\n",
        "        tf.ragged.constant(pair_indices_list, dtype=tf.int64),\n",
        "    )\n",
        "\n",
        "\n",
        "# Shuffle array of indices ranging from 0 to 2049\n",
        "permuted_indices = np.random.permutation(np.arange(dataset.shape[0]))\n",
        "\n",
        "# Train set: 80 % of data\n",
        "train_index = permuted_indices[: int(dataset.shape[0] * 0.8)]\n",
        "x_train = graphs_from_smiles(dataset.iloc[train_index].Smiles)\n",
        "y_train = dataset.iloc[train_index].Tb\n",
        "\n",
        "# Valid set: 10 % of data\n",
        "valid_index = permuted_indices[int(dataset.shape[0] * 0.8) : int(dataset.shape[0] * 0.9)]\n",
        "x_valid = graphs_from_smiles(dataset.iloc[valid_index].Smiles)\n",
        "y_valid = dataset.iloc[valid_index].Tb\n",
        "\n",
        "# Test set: 10 % of data\n",
        "test_index = permuted_indices[int(dataset.shape[0] * 0.9) :]\n",
        "x_test = graphs_from_smiles(dataset.iloc[test_index].Smiles)\n",
        "y_test = dataset.iloc[test_index].Tb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy2ozCSNDz97"
      },
      "source": [
        "### Test the functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "afXA5mJDDz97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SMILES String:\tFCF\n",
            "Boiling Point:\t221.55\n",
            "Molecule:\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAACWCAIAAADCEh9HAAAABmJLR0QA/wD/AP+gvaeTAAAQZ0lEQVR4nO3da3BTZ3oH8Ofo4ot8w5ZtybIO14C5J6VhWW9IJiRMs1ymtLRk00y8yXQ3TiBTEzAdZ/ohnsknJTHU7KyTmpSZaNvuJrCTds0EZocEBggpNcQN90sIsX0kIVmWHV0tWdI5/XCQljpgZB9JR5f/76NHkp+RrL/P5XmflxEEgQAAYLoUchcAAJDdEKMAAJIgRgEAJEGMAgBIghgFAJAEMQoAIAliFABAEsQoAIAkiFEAAEkQowAAkiBGAQAkQYwCAEiCGAUAkESV6l/gDIcd4+NTegpbWFihSnlhAJB13JEIFwpN6Sm6goIatTpF9YhSnlaHhoffs9mm9JS35sxZX1WVonoAIHud9nje/O67KT1lm8Hw93V1KapHhJN6AABJEKMAAJKk9RKkae7cJ2bMeODDVAyThmIAIKttNxp/Vlv7wIelIePSGqNKhilARAJAMiiJMiRPcFIPACAJYhQAQBLEKACAJIhRAABJEKMAAJIgRgEAJElrw9M5r9cXjU7ygEKG+QssAwWABFwOBA65XJM/Zn1VlTL1TVFpjdGPh4Ymf8AMlQoxCgCJ+OPIyB9HRiZ/zNrKyuLUxyhO6gEAJEnr0WiZUqlWTBbcMzAfDwASo1EqiybNE0rXcWJaY+vN2bPXJLCmHgDggV6tq3tep5O7CiKc1AMASIQYBQCQBDEKACAJYhQAQBLEKACAJIhRAABJsiZGPx4a2nHzpm2KezUDQNYZCoff7O8/4HTKXUiisqPdPSIIZrt9KBw+e/nyi3r9z3W6wge13QJA1gnx/G8cDrPdHuT5cx7P5urqrNiZLTvCSMUwHy5cuF6rDfF8t83215cufepyCXJXBQBJdNLt3nLlSrfNFuT5xysq/rWhISsylLLlaJSIagsK3po9+9mamt0cd9Hvb+/vP+B07mLZZSUlcpcGAJJcDwR2c1yfz0dEDRpNK8uuKC2Vu6gpyJoYFS0tKdm/cOERl2uv1XrZ7//FtWs/1Wpfr6+vUqvlLg0ApswdiXxw+/YBp5MXhAqV6pd1dT+rqVFkyUFoXJbFKBEpiDZotWsqK//dbv/Qbj/sch0fHW3S6V6qq8uQ3VYB4IEignDQ6ey22XzRqIphnq2tfdVgKFUq5a5rOhhBSO01xgDPx0c1z1AqC5J6a2gwFHrPav1sdJSI2MLC1+rr11ZWJvH1ASAVej2eDo67FQwS0Y/Ky3cZjXOLixN5Yojn3bE8KVMqizPjVnPKYzQNer3e3Rz37dgYEf2orKyVZecl9pEAQJoNBoN7LJYv3G4imllUtNNoXF1RIXdRUuVCjBJRVBD+4HK9Z7V+H4koGWaTVrutvh7TSwEyhzca/dBu/63DERaEMqXyJb3+eZ1OnRMX4nIkRkWeSGTf7dsHnc6oIJSrVC/X1T1bU5OGnVgAYBI80RGXa6/FMhKJKIh+qtW+bjRW5dBRTk7FqKg/GNzDcV96PEQ0u6hoJ8v+pLxc7qIA8tQ5r3cPx90YGyOiPy8ra2XZBTl3zS0HY1R00u3ezXHWUIiIHq+o2MWy9YWFchcFkEcc4+NdNtthl4uIdAUF2wyGDVqt3EWlRM7GKBGFBeH3Tue/2Gz+aFTNMH9TU7PVYCjJzo4KgCwyxvP/Zrd/6HCM83yRQvFzne4lvT65XToZJZdjVDQcDu+z2f5reJgnqlarmw2Gv6quztnPE0BWAtHno6OdFot9fJwherqy8nWjUV9QIHddqZX7MSq6Ggh0cNx5n4+IFmk0u1j24axabQaQ+a4EAh0cd8HnI6LFGs0ull2eH9+yfIlRiv2f3Gux3I79n9xuNNbl+v9JgDRwhsMfxM75atTql/PsnC+PYlQU5Pnf/P+rNi/q9Ri7BzA94h2I9222QOwOxDaDQZNndyDyLkZFQ+Pjv7bZjrhcAlFtQcFrBsN6rRb9pQBTgn4YUZ7GqKjP6+2IdbStKCvbZTQu0GjkLgogC3wXDO7huP/2eIhoTlHRTpZtzOPu7LyOUbrn+gqM3QO4P3GtoDjaTlwrmI2j7ZIr32NUJK72/Z3DMR5b7ft3Oh3G7gHcLSIIPbHJFSqG+UtMrohBjP7JYDD4zxbLKXH2TGHhDpZ9PPtnzwAkRa/H02Gx3BLnqJWXtxqNmKMWhxidaMKfS+KTEAFy0t1TfWcWFm7DVN8fQIzegziXe5/N5o1GcfICeevui10aheIF7DFxH4jR+8KldMhbd269Wq0j4TBuvT4QYvQBbgQCHRZLn9dLaOyA/NDn9XZYLDcCASJaWlKyi2WXYv/dSSFGE3LS7e7gOFuszfgfWdaQl23GkNuwLGV6EKOJwqI3yGHiImmzwxHCIumpQ4xOTZ6PYIDcg5E90iFGp+OK399hseThQDDIMRMGSLay7CP4S546xOg05ed4WsgZ9xhnrtWiEWV6EKOS3L1ZQrFC0ZTrmyVADhDbosXNdVQM87fYXEcyxGgS5M/WXZDtTrrdezjOEus5aWVZI3pOJEOMJs05r3c3x30zNkZEj5aVtbLsfKwihYwxceNxo/EnGBmRJIjRZLrH2D2jsQqrSEFW4nq8g05nVBDKlcqXDYZna2qUuAyaPIjR5PNEo2a7/bcORzg2du95nU6Nv1pIu6gg/CE22k7JMJu02q319ZX4v55siNFUGQgG91gsp8Wxe0VFO43G1TiHgjTq9Xr3cNzNsTEiWllW1sqyD+EqU2ogRlOr1+Pp4LhbwSCJY/dYdm5RkdxFQY7jQqGu2Gg7trDwNYy2SzHEaMqJ/SXdNpsv1l/yqsFQiv4SSIE7HXh2+7gg3OnAw2i71EOMpok7EvkgNnavQqX6JcbuQVKJtzd/ZbW6wmGGaJ1Wu72+XovRdmmBGE2r64FAB8f9r89HRA0aTSvLrsDaO5Dsst/fwXEX/X4iWlJSsotll2G0XRohRmVw0u3uGBy0jY+TOHZv5kwDVpHCtAyFw7+2Wu+MtlOrX6uvx2i79EOMyiPE8x8NDe2/fTvA84UKxXO1tb/Q6zF2DxIX5PmPJ/wJ1dVpsBBZDohROeFQAqYHJzQZBTEqv8t+/26Ou+D3E9HikpJdLLscF7bgPq4FArtjl9cXajStLPtnuLwuN8RoRhCIDuM2K0wKzR4ZCzGaQe7R9Iexe4DW44yHGM04WIICd8NCuMyHGM1QZzyePbEvz6ry8haVqmHOHLmLgrS6fuvWr6LR//F4iGhuUdFOlv0xNvfOSDhhzFA/Li//3eLF/zRrVqVKNTo0tHTBgldeecXpdMpdF6TD6OjoG2+8sXzRIsuJE+VK5T/U1//H4sXI0IyFGM1cSobZXF39+yVL5p89S0T79u1btGhRV1dXJBKRuzRIlUgk0tXVNX/+/Lfffpvn+WUOx38uXfqiXo9BixlNgGxw9erVdevWiR9ZQ0PD4cOH5a4Iku/YsWPLly8XP+U1a9acP39e7oogIYjRbNLT0zNv3jzxa7Zx48abN2/KXREkx8DAQFNTk/jJsixrNpvlrgimADGaZcbHxzs7O8vLy4lIrVa3tLS43W65i4Lp8/l87e3tRUVFRFRSUtLe3j42NiZ3UTA1iNGsZLPZmpublUolEVVXV3d2dkYiEbmLgqnhed5sNuv1eiJiGGbLli2Dg4NyFwXTgRjNYl999dXq1avFM8EVK1acOnVK7oogUb29vY2NjeJnt3Llyi+//FLuimD6EKPZjef5AwcOzJo1K37BtL+/X+6iYDJWq7WpqYlhGCIyGAzd3d3RaFTuokASxGgu8Pv9JpOptLSUiDQaTVtbm9frlbsomCgQCJhMprKyMiIqLi5ua2vzeDxyFwVJgBjNHRzHxQ9zjEaj2WzmeV7uouCOnp6eObF1aBs3brx165bcFUHSIEZzzZkzZ1atWiV+XVetWnXmzBm5K8p3fX19TzzxhPiJPPLIIydOnJC7IkgyxGgOikajZrNZp9MRkUKhaGpqstvtcheVj4aHh1taWsSGCq1Wi4aKXIUYzVler7e9vb2wsJCISktL29vbg8Gg3EXlC7G9t6KiIt7e+/3338tdFKQKYjTH3bhxY8uWLeIZ5fz58w8cOCB3Rbnv6NGjS5YsEd/ztWvXXrp0Se6KILUQo3nhs88+W7p0qfjFfvrppy9evCh3Rbnp+vXrGzZsEN/nBQsWHDp0SO6KIB0Qo/kiHA53d3dXV1cTkUqlam5udjqdcheVO0ZHR9va2goKCohoxowZJpMJl1DyB2I0v7hcrvhNj6qqqs7OznA4LHdR2U28oVdbWxu/oedwOOQuCtIKMZqPrly58swzz4jnngsXLjxy5IjcFWWr48ePP/zww+I7+eSTT3799ddyVwQyQIzmr56enrlz58Ybwr/99lu5K8omg4ODE0bbYbFD3kKM5rVQKBQfu1dQUICxe4nw+/3x0XYajQaj7QAxCoLVam1ublYoFERUV1eHYRn3Iw6CmTlzZny03cDAgNxFgfwQo3DH2bNnH3vsMfEs9dFHH/3iiy/kriiz4P2B+0GMwp/gaOuecLQOk0OMwkS49heHa8eQCMQo3Nvdd6Lzc+weOhkgQYhRmEx+9kWirxamBDEKD5BXq3SwygumATEKCcn5NeOYOQDThhiFKcjVCUaYgAVSIEZhynJpnibmsYJ0iFGYjhyY7o7dASBZEKMwfVm61xD2qoLkQoyCVNm18yV2ToWkQ4xCcmT+PuwcxzU1NTEMk7cLCiBFEKOQNIFAwGQylZWVEVFxcXFbW5vH45G7KEEQBL/fbzKZSktLxeWtbW1tXq9X7qIgdyBGIcmsVmv8oM9gMMg7yEMctjJr1qz4YXJ/f79cxUCuQoxCSvT29jY2NorhtXLlytOnT6e/hnPnzq1evVqsYcWKFadOnUp/DZAPEKOQKjzPm81mvV4fH7s3ODiYnl9ts9mam5vFFoLq6upsaSGALIUYhdTy+XzxsXslJSWpHrsnNrSKo+3EhlaMtoNUQ4xCOgwMDEzYAC4Vv6Wnp2fevHnxy6A3b95MxW8BmAAxCulz7Nix5cuXizG3Zs2a8+fPJ+uVr169um7dOvGVGxoaDh8+nKxXBnggxCiklbiCqKamJllj90ZGRlpaWlQqFRFVVlZitB2kH2IUZDAyMhIfu1dZWWkymUKh0FRfRBxtJyayONpuaGgoFdUCTA4xCrK5du3a+vXr42fin376aeLP/fzzz5ctWyY+96mnnrpw4ULq6gSYHGIUZHb06NHFixfHx+5dvnx58sd/88038dF2Dz30EEbbgewQoyC/H47dGxkZ+eHDPB5PfLRdGnqnABLECIJAABnA5XK99dZbXV1d0WhUoVBs2rTpo48+Eq+f8jy/devW/fv3R6NRhmFeeOGFd955R2zsB5AdYhQyS19f3+bNmwcGBohIo9G8++67arV6x44dfr+fiOrr6w8ePBhfZgqQCRCjkHF4nt++ffv7778fjUbjP1QqlVu3bt27d69CoZCxNoAfQoxChhoeHn7uueeOHz9ORI2NjZ988om4yTNApkGMQkbz+XxEJI4KBchMiFEAAElwmQkAQBLEKACAJIhRAABJEKMAAJIgRgEAJEGMAgBIghgFAJAEMQoAIAliFABAEsQoAIAkiFEAAEkQowAAkvwfz20+fTb2dDUAAABoelRYdHJka2l0UEtMIHJka2l0IDIwMjIuMDkuNAAAeJx7v2/tPQYg4GWAAEYgZgZiJiBuYORkUACJsTEkgISYoFxuoCpGJgYRBnE9qA4wYH7otsweqMsOxFm9SmspkNoPYgPF98PExQCpfw4ErvZebQAAAKp6VFh0TU9MIHJka2l0IDIwMjIuMDkuNAAAeJyNUMsKwyAQvPsV8wORzUqgHqMmpYQotLb/0Hv/n64E8zg0dNfD7DAzDCqUuYfp/cE6HJQC6ORZa/EyRKRmFAA3XG8RPveuMj49Y37AgMUhe1T2Oc2VaTGi1WwtmQtIcye5YtBEC6g6hkez0oI6+qE0ktj8EznEcKiylHMphq1cWd46yAGz9+/V5a6fIFh9ASNSQ1o2p42JAAAAP3pUWHRTTUlMRVMgcmRraXQgMjAyMi4wOS40AAB4nHNzdlOo0TDUM7K0NDDRMdAzMtWxNtDRNdAD0roowpo1ANE+CSxGkbIuAAAAAElFTkSuQmCC",
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x1b100c45e00>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f\"SMILES String:\\t{dataset.Smiles[100]}\\nBoiling Point:\\t{dataset.Tb[100]}\")\n",
        "molecule = molecule_from_smiles(dataset.iloc[100].Smiles)\n",
        "print(\"Molecule:\")\n",
        "molecule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bBbxl8jLDz98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph (including self-loops):\n",
            "\tatom features\t (3, 39)\n",
            "\tbond features\t (7, 13)\n",
            "\tpair indices\t (7, 2)\n"
          ]
        }
      ],
      "source": [
        "graph = graph_from_molecule(molecule)\n",
        "print(\"Graph (including self-loops):\")\n",
        "print(\"\\tatom features\\t\", graph[0].shape)\n",
        "print(\"\\tbond features\\t\", graph[1].shape)\n",
        "print(\"\\tpair indices\\t\", graph[2].shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U073X9WDz98"
      },
      "source": [
        "### Create a `tf.data.Dataset`\n",
        "\n",
        "In this tutorial, the MPNN implementation will take as input (per iteration) a single graph.\n",
        "Therefore, given a batch of (sub)graphs (molecules), we need to merge them into a\n",
        "single graph (we'll refer to this graph as *global graph*).\n",
        "This global graph is a disconnected graph where each subgraph is\n",
        "completely separated from the other subgraphs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "TxrlHlUYDz98"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prepare_batch(x_batch, y_batch):\n",
        "    \"\"\"Merges (sub)graphs of batch into a single global (disconnected) graph\n",
        "    \"\"\"\n",
        "\n",
        "    atom_features, bond_features, pair_indices = x_batch\n",
        "\n",
        "    # Obtain number of atoms and bonds for each graph (molecule)\n",
        "    num_atoms = atom_features.row_lengths()\n",
        "    num_bonds = bond_features.row_lengths()\n",
        "\n",
        "    # Obtain partition indices (molecule_indicator), which will be used to\n",
        "    # gather (sub)graphs from global graph in model later on\n",
        "    molecule_indices = tf.range(len(num_atoms))\n",
        "    molecule_indicator = tf.repeat(molecule_indices, num_atoms)\n",
        "\n",
        "    # Merge (sub)graphs into a global (disconnected) graph. Adding 'increment' to\n",
        "    # 'pair_indices' (and merging ragged tensors) actualizes the global graph\n",
        "    gather_indices = tf.repeat(molecule_indices[:-1], num_bonds[1:])\n",
        "    increment = tf.cumsum(num_atoms[:-1])\n",
        "    increment = tf.pad(tf.gather(increment, gather_indices), [(num_bonds[0], 0)])\n",
        "    pair_indices = pair_indices.merge_dims(outer_axis=0, inner_axis=1).to_tensor()\n",
        "    pair_indices = pair_indices + increment[:, tf.newaxis]\n",
        "    atom_features = atom_features.merge_dims(outer_axis=0, inner_axis=1).to_tensor()\n",
        "    bond_features = bond_features.merge_dims(outer_axis=0, inner_axis=1).to_tensor()\n",
        "\n",
        "    return (atom_features, bond_features, pair_indices, molecule_indicator), y_batch\n",
        "\n",
        "\n",
        "def MPNNDataset(X, y, batch_size=32, shuffle=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, (y)))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(1024)\n",
        "    return dataset.batch(batch_size).map(prepare_batch, -1).prefetch(-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ow4zAHyDz99"
      },
      "source": [
        "## Model\n",
        "\n",
        "The MPNN model can take on various shapes and forms. In this tutorial, we will implement an\n",
        "MPNN based on the original paper\n",
        "[Neural Message Passing for Quantum Chemistry](https://arxiv.org/abs/1704.01212) and\n",
        "[DeepChem's MPNNModel](https://deepchem.readthedocs.io/en/latest/api_reference/models.html#mpnnmodel).\n",
        "The MPNN of this tutorial consists of three stages: message passing, readout and\n",
        "classification.\n",
        "\n",
        "\n",
        "### Message passing\n",
        "\n",
        "The message passing step itself consists of two parts:\n",
        "\n",
        "1. The *edge network*, which passes messages from 1-hop neighbors `w_{i}` of `v`\n",
        "to `v`, based on the edge features between them (`e_{vw_{i}}`),\n",
        "resulting in an updated node (state) `v'`. `w_{i}` denotes the `i:th` neighbor of\n",
        "`v`.\n",
        "\n",
        "2. The *gated recurrent unit* (GRU), which takes as input the most recent node state\n",
        "and updates it based on previous node states. In\n",
        "other words, the most recent node state serves as the input to the GRU, while the previous\n",
        "node states are incorporated within the memory state of the GRU. This allows information\n",
        "to travel from one node state (e.g., `v`) to another (e.g., `v''`).\n",
        "\n",
        "Importantly, step (1) and (2) are repeated for `k steps`, and where at each step `1...k`,\n",
        "the radius (or number of hops) of aggregated information from `v` increases by 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "2zlSQ3plDz99"
      },
      "outputs": [],
      "source": [
        "\n",
        "class EdgeNetwork(layers.Layer):\n",
        "    def build(self, input_shape):\n",
        "        self.atom_dim = input_shape[0][-1]\n",
        "        self.bond_dim = input_shape[1][-1]\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(self.bond_dim, self.atom_dim * self.atom_dim),\n",
        "            initializer=\"glorot_uniform\",\n",
        "            name=\"kernel\",\n",
        "        )\n",
        "        self.bias = self.add_weight(\n",
        "            shape=(self.atom_dim * self.atom_dim), initializer=\"zeros\", name=\"bias\",\n",
        "        )\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        atom_features, bond_features, pair_indices = inputs\n",
        "\n",
        "        # Apply linear transformation to bond features\n",
        "        bond_features = tf.matmul(bond_features, self.kernel) + self.bias\n",
        "\n",
        "        # Reshape for neighborhood aggregation later\n",
        "        bond_features = tf.reshape(bond_features, (-1, self.atom_dim, self.atom_dim))\n",
        "\n",
        "        # Obtain atom features of neighbors\n",
        "        atom_features_neighbors = tf.gather(atom_features, pair_indices[:, 1])\n",
        "        atom_features_neighbors = tf.expand_dims(atom_features_neighbors, axis=-1)\n",
        "\n",
        "        # Apply neighborhood aggregation\n",
        "        transformed_features = tf.matmul(bond_features, atom_features_neighbors)\n",
        "        transformed_features = tf.squeeze(transformed_features, axis=-1)\n",
        "        aggregated_features = tf.math.unsorted_segment_sum(\n",
        "            transformed_features,\n",
        "            pair_indices[:, 0],\n",
        "            num_segments=tf.shape(atom_features)[0],\n",
        "        )\n",
        "        return aggregated_features\n",
        "\n",
        "\n",
        "class MessagePassing(layers.Layer):\n",
        "    def __init__(self, units, steps=4, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.steps = steps\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.atom_dim = input_shape[0][-1]\n",
        "        self.message_step = EdgeNetwork()\n",
        "        self.pad_length = max(0, self.units - self.atom_dim)\n",
        "        self.update_step = layers.GRUCell(self.atom_dim + self.pad_length)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        atom_features, bond_features, pair_indices = inputs\n",
        "\n",
        "        # Pad atom features if number of desired units exceeds atom_features dim.\n",
        "        # Alternatively, a dense layer could be used here.\n",
        "        atom_features_updated = tf.pad(atom_features, [(0, 0), (0, self.pad_length)])\n",
        "\n",
        "        # Perform a number of steps of message passing\n",
        "        for i in range(self.steps):\n",
        "            # Aggregate information from neighbors\n",
        "            atom_features_aggregated = self.message_step(\n",
        "                [atom_features_updated, bond_features, pair_indices]\n",
        "            )\n",
        "\n",
        "            # Update node state via a step of GRU\n",
        "            atom_features_updated, _ = self.update_step(\n",
        "                atom_features_aggregated, atom_features_updated\n",
        "            )\n",
        "        return atom_features_updated\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwTDUQnyDz99"
      },
      "source": [
        "### Readout\n",
        "\n",
        "When the message passing procedure ends, the k-step-aggregated node states are to be partitioned\n",
        "into subgraphs (correspoding to each molecule in the batch) and subsequently\n",
        "reduced to graph-level embeddings. In the\n",
        "[original paper](https://arxiv.org/abs/1704.01212), a\n",
        "[set-to-set layer](https://arxiv.org/abs/1511.06391) was used for this purpose.\n",
        "In this tutorial however, a transformer encoder + average pooling will be used. Specifically:\n",
        "\n",
        "* the k-step-aggregated node states will be partitioned into the subgraphs\n",
        "(corresponding to each molecule in the batch);\n",
        "* each subgraph will then be padded to match the subgraph with the greatest number of nodes, followed\n",
        "by a `tf.stack(...)`;\n",
        "* the (stacked padded) tensor, encoding subgraphs (each subgraph containing a set of node states), are\n",
        "masked to make sure the paddings don't interfere with training;\n",
        "* finally, the tensor is passed to the transformer followed by average pooling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "2vJ2fQsmDz99"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PartitionPadding(layers.Layer):\n",
        "    def __init__(self, batch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        atom_features, molecule_indicator = inputs\n",
        "\n",
        "        # Obtain subgraphs\n",
        "        atom_features_partitioned = tf.dynamic_partition(\n",
        "            atom_features, molecule_indicator, self.batch_size\n",
        "        )\n",
        "\n",
        "        # Pad and stack subgraphs\n",
        "        num_atoms = [tf.shape(f)[0] for f in atom_features_partitioned]\n",
        "        max_num_atoms = tf.reduce_max(num_atoms)\n",
        "        atom_features_stacked = tf.stack(\n",
        "            [\n",
        "                tf.pad(f, [(0, max_num_atoms - n), (0, 0)])\n",
        "                for f, n in zip(atom_features_partitioned, num_atoms)\n",
        "            ],\n",
        "            axis=0,\n",
        "        )\n",
        "\n",
        "        # Remove empty subgraphs (usually for last batch in dataset)\n",
        "        gather_indices = tf.where(tf.reduce_sum(atom_features_stacked, (1, 2)) != 0)\n",
        "        gather_indices = tf.squeeze(gather_indices, axis=-1)\n",
        "        return tf.gather(atom_features_stacked, gather_indices, axis=0)\n",
        "\n",
        "\n",
        "class TransformerEncoderReadout(layers.Layer):\n",
        "    def __init__(\n",
        "        self, num_heads=8, embed_dim=64, dense_dim=512, batch_size=32, **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.partition_padding = PartitionPadding(batch_size)\n",
        "        self.attention = layers.MultiHeadAttention(num_heads, embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.average_pooling = layers.GlobalAveragePooling1D()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.partition_padding(inputs)\n",
        "        padding_mask = tf.reduce_any(tf.not_equal(x, 0.0), axis=-1)\n",
        "        padding_mask = padding_mask[:, tf.newaxis, tf.newaxis, :]\n",
        "        attention_output = self.attention(x, x, attention_mask=padding_mask)\n",
        "        proj_input = self.layernorm_1(x + attention_output)\n",
        "        proj_output = self.layernorm_2(proj_input + self.dense_proj(proj_input))\n",
        "        return self.average_pooling(proj_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6JSpoqFDz9-"
      },
      "source": [
        "### Message Passing Neural Network (MPNN)\n",
        "\n",
        "It is now time to complete the MPNN model. In addition to the message passing\n",
        "and readout, a two-layer classification network will be implemented to make\n",
        "predictions of BBBP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "jSkNBHvwDz9-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def MPNNModel(\n",
        "    atom_dim,\n",
        "    bond_dim,\n",
        "    batch_size=32,\n",
        "    message_units=64,\n",
        "    message_steps=4,\n",
        "    num_attention_heads=8,\n",
        "    dense_units=512,\n",
        "):\n",
        "\n",
        "    atom_features = layers.Input((atom_dim), dtype=\"float32\", name=\"atom_features\")\n",
        "    bond_features = layers.Input((bond_dim), dtype=\"float32\", name=\"bond_features\")\n",
        "    pair_indices = layers.Input((2), dtype=\"int32\", name=\"pair_indices\")\n",
        "    molecule_indicator = layers.Input((), dtype=\"int32\", name=\"molecule_indicator\")\n",
        "\n",
        "    x = MessagePassing(message_units, message_steps)(\n",
        "        [atom_features, bond_features, pair_indices]\n",
        "    )\n",
        "\n",
        "    x = TransformerEncoderReadout(\n",
        "        num_attention_heads, message_units, dense_units, batch_size\n",
        "    )([x, molecule_indicator])\n",
        "\n",
        "    x = layers.Dense(dense_units, activation=\"relu\")(x)\n",
        "    x = layers.Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[atom_features, bond_features, pair_indices, molecule_indicator],\n",
        "        outputs=[x],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "mpnn = MPNNModel(\n",
        "    atom_dim=x_train[0][0][0].shape[0], bond_dim=x_train[1][0][0].shape[0],\n",
        ")\n",
        "\n",
        "mpnn.compile(\n",
        "    loss=keras.losses.MeanSquaredError(),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
        "    metrics=[keras.metrics.RootMeanSquaredError(name=\"root_mean_squared_error\", dtype=None)],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Gyo4pmDz9-"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "lxw7y5kuDz9_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "132/132 - 19s - loss: 166503.3125 - root_mean_squared_error: 408.0482 - val_loss: 75682.2031 - val_root_mean_squared_error: 275.1040 - 19s/epoch - 142ms/step\n",
            "Epoch 2/40\n",
            "132/132 - 14s - loss: 26467.8555 - root_mean_squared_error: 162.6894 - val_loss: 7683.9395 - val_root_mean_squared_error: 87.6581 - 14s/epoch - 103ms/step\n",
            "Epoch 3/40\n",
            "132/132 - 13s - loss: 5913.3281 - root_mean_squared_error: 76.8982 - val_loss: 3258.7234 - val_root_mean_squared_error: 57.0852 - 13s/epoch - 101ms/step\n",
            "Epoch 4/40\n",
            "132/132 - 12s - loss: 3952.9751 - root_mean_squared_error: 62.8727 - val_loss: 2540.1289 - val_root_mean_squared_error: 50.3997 - 12s/epoch - 95ms/step\n",
            "Epoch 5/40\n",
            "132/132 - 13s - loss: 3406.0503 - root_mean_squared_error: 58.3614 - val_loss: 2403.4214 - val_root_mean_squared_error: 49.0247 - 13s/epoch - 96ms/step\n",
            "Epoch 6/40\n",
            "132/132 - 13s - loss: 3097.0266 - root_mean_squared_error: 55.6509 - val_loss: 2536.0459 - val_root_mean_squared_error: 50.3592 - 13s/epoch - 96ms/step\n",
            "Epoch 7/40\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[43], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m valid_dataset \u001b[39m=\u001b[39m MPNNDataset(x_valid, y_valid)\n\u001b[0;32m      3\u001b[0m test_dataset \u001b[39m=\u001b[39m MPNNDataset(x_test, y_test)\n\u001b[1;32m----> 5\u001b[0m history \u001b[39m=\u001b[39m mpnn\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      6\u001b[0m     train_dataset,\n\u001b[0;32m      7\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalid_dataset,\n\u001b[0;32m      8\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mplt.figure(figsize=(10, 6))\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39mplt.plot(history.history[\"AUC\"], label=\"train AUC\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mplt.legend(fontsize=16)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m'''\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\kanad\\Desktop\\Github repos\\ME_793_PROJECT\\793_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\kanad\\Desktop\\Github repos\\ME_793_PROJECT\\793_env\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mc:\\Users\\kanad\\Desktop\\Github repos\\ME_793_PROJECT\\793_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\kanad\\Desktop\\Github repos\\ME_793_PROJECT\\793_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\kanad\\Desktop\\Github repos\\ME_793_PROJECT\\793_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\kanad\\Desktop\\Github repos\\ME_793_PROJECT\\793_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[1;32mc:\\Users\\kanad\\Desktop\\Github repos\\ME_793_PROJECT\\793_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\kanad\\Desktop\\Github repos\\ME_793_PROJECT\\793_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32mc:\\Users\\kanad\\Desktop\\Github repos\\ME_793_PROJECT\\793_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_dataset = MPNNDataset(x_train, y_train)\n",
        "valid_dataset = MPNNDataset(x_valid, y_valid)\n",
        "test_dataset = MPNNDataset(x_test, y_test)\n",
        "\n",
        "history = mpnn.fit(\n",
        "    train_dataset,\n",
        "    validation_data=valid_dataset,\n",
        "    epochs=40,\n",
        "    verbose=2,\n",
        ")\n",
        "'''\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history[\"AUC\"], label=\"train AUC\")\n",
        "plt.plot(history.history[\"val_AUC\"], label=\"valid AUC\")\n",
        "plt.xlabel(\"Epochs\", fontsize=16)\n",
        "plt.ylabel(\"AUC\", fontsize=16)\n",
        "plt.legend(fontsize=16)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RmnuvprDz9_"
      },
      "source": [
        "### Predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EfHVOIqDz-A"
      },
      "outputs": [],
      "source": [
        "molecules = [molecule_from_smiles(df.smiles.values[index]) for index in test_index]\n",
        "y_true = [df.p_np.values[index] for index in test_index]\n",
        "y_pred = tf.squeeze(mpnn.predict(test_dataset), axis=1)\n",
        "\n",
        "legends = [f\"y_true/y_pred = {y_true[i]}/{y_pred[i]:.2f}\" for i in range(len(y_true))]\n",
        "MolsToGridImage(molecules, molsPerRow=4, legends=legends)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPnrnWGmDz-A"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "In this tutorial, we demonstarted a message passing neural network (MPNN) to\n",
        "predict blood-brain barrier permeability (BBBP) for a number of different molecules. We\n",
        "first had to construct graphs from SMILES, then build a Keras model that could\n",
        "operate on these graphs, and finally train the model to make the predictions.\n",
        "\n",
        "Example available on HuggingFace\n",
        "\n",
        "| Trained Model | Demo |\n",
        "| :--: | :--: |\n",
        "| [![Generic badge](https://img.shields.io/badge/%F0%9F%A4%97%20Model-mpnn%20molecular%20graphs-black.svg)](https://huggingface.co/keras-io/MPNN-for-molecular-property-prediction) | [![Generic badge](https://img.shields.io/badge/%F0%9F%A4%97%20Spaces-mpnn%20molecular%20graphs-black.svg)](https://huggingface.co/spaces/keras-io/molecular-property-prediction) |"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mpnn-molecular-graphs",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "793_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "c3501b5041c5233f2ce1d5f142327998ccbd12e95b6317deec921834a08ecc96"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
